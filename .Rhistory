}
}
num_views <- 10
interpret <- function(num_views) {
if (num_views > 15) {
print("You're popular!") & print(num_views)
} else { print("Try to be more visible!") & print(0)
}
}
15
num_views <- 16
interpret <- function(num_views) {
if (num_views > 15) {
print("You're popular!") & print(num_views)
} else { print("Try to be more visible!") & print(0)
num_views >- 16
num_views ->  16
if (num_views > 15) {
print("You're popular!") & print(num_views)
} else { print("Try to be more visible!") & print(0)
num_views ->  16
}
interpret <- function(num_views) {
if (num_views > 15) {
print("You're popular!") & print(num_views)
} else { print("Try to be more visible!") & print(0)
num_views ->  16
}
}
num_views <- 16
num_views
interpet(linkedin[1])
interpet(linkedin[1])
interpret <- function(num_views) {
if (num_views > 15)
print("You're popular!") & print(num_views)
} else print("Try to be more visible!") & print(0)
# Part 5. Call the interpret() function twice: on the first value of the linkedin vector and on the second element of
#         the facebook vector. The linkedin and facebook vectors have already been created for you
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
facebook <- c(17, 7, 5, 16, 8, 13, 14)
interpet(linkedin[1])
interpret <- function(num_views) {
if (num_views > 15)
print("You're popular!") & print(num_views)
} else print("Try to be more visible!") & print(0)
# Part 5. Call the interpret() function twice: on the first value of the linkedin vector and on the second element of
#         the facebook vector. The linkedin and facebook vectors have already been created for you
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
facebook <- c(17, 7, 5, 16, 8, 13, 14)
interpet(linkedin[1])
interpret <- function(num_views) {
if (num_views > 15)
print("You're popular!") & print(num_views)
} else print("Try to be more visible!") & print(0)
# Part 5. Call the interpret() function twice: on the first value of the linkedin vector and on the second element of
#         the facebook vector. The linkedin and facebook vectors have already been created for you
linkedin <- c(16, 9, 13, 5, 2, 17, 14)
facebook <- c(17, 7, 5, 16, 8, 13, 14)
interpet(linkedin[1])
interpret(facebook)
rock_paper_scissors("rock","rock") == "Tie"
rock_paper_scissors("rock","paper") == "Player 1"
rock_paper_scissors("scissors","rock") == "Player 2"
rock_paper_scissors <- function(player_1, player_2){
# use the if else if else structure we discussed in class
if ( {player_1 <- "rock" & player_2 <- "scissors"})
(player_1 <- "scissors" & player_2 <- "paper")
(player_1 <- "paper" & player_2 <- "rock")
winner <- player_1
return(winner)
} else if (player_1 <- "rock" & player_2 <- "paper") {
(player_1 <- "scissors" & player_2 <- "rock")
([player_1 <- "paper" & player_2 <- "scissors"])
winner <- player_2
return(winner)
} else {
winner <- Tie
return(winner)
}
}
# test the results
rock_paper_scissors("rock","rock") == "Tie"
rock_paper_scissors("rock","paper") == "Player 1"
rock_paper_scissors("scissors","rock") == "Player 2"
rock_paper_scissors <- function(player_1, player_2){
# use the if else if else structure we discussed in class
if ( {player_1 <- "rock" & player_2 <- "scissors"})
(player_1 <- "scissors" & player_2 <- "paper")
(player_1 <- "paper" & player_2 <- "rock")
winner <- player_1
return(winner)
} else if (player_1 <- "rock" & player_2 <- "paper") {
(player_1 <- "scissors" & player_2 <- "rock")
([player_1 <- "paper" & player_2 <- "scissors"])
winner <- player_2
return(winner)
} else {
winner <- Tie
return(winner)
}
rock_paper_scissors <- function(player_1, player_2)
if (player_1==player_2) {
winner <- Tie
} else if ((player_1 == "rock" & player_2 == "paper") |
(player_1 == "scissors" & player_2 == "rock") |
(player_1 == "paper" & player_2 == "scissors")) {
winner <- player_2
} else
if ( {player_1 == "rock" & player_2 == "scissors"})
(player_1 == "scissors" & player_2 == "paper")
(player_1 == "paper" & player_2 == "rock")
winner <- player_1
return(winner)
# test the results
rock_paper_scissors("rock","rock") == "Tie"
rock_paper_scissors("rock","paper") == "Player 1"
rock_paper_scissors("scissors","rock") == "Player 2"
frb_chair <- data.frame(surnae, appointed, has_beard)
length(x)==n
all(i<=n)
x[i]
rock_paper_scissors("rock","paper") == "Player 1
dw <- c("S","M", "T","W","Tr","F","Sa")
dow <-  c("S","M", "T","W","Tr","F","Sa")
print(dow)
dow[-5]
C("foo", "bar", "we")
nchar(dow_ == 1)
grep('S', dow)
dow[grep('S',dow)]
dow[TRUE]
dow[c(1:5,5:1)]
dow$3
L<- list(a = 1, b = 2, c= 3)
L
str(L)
$1
$a
L$a
L$a
paste(frb[1])
paste(dow[1])
paste(dow)
for( i in 1:nrow(dow) )
paste(dow,x)
paste(dow,2)
paste(dow,123)
mtcars <- read.csv("mtcars.csv", stringsAsFactors = FALSE)
data(mtcars)
view(mtcars)
mtcars
mtcars
mtcars
mtcars
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
read.csv(data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework" )
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
?read.csv
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
str(hmda)
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
read.csv("hmda")
str(hmda)
str(hmda)
hmda
source('~/JonesVIctor Homework 4.R')
source('~/JonesVIctor Homework 4.R')
source('~/JonesVIctor Homework 4.R')
read.csv("hmda", header = TRUE, sep = " ", quote = "/" ", dec = ".", fill = TRUE, comment.char = ")
read.csv("hmda", header = TRUE, sep = " ", quote = "/" ", dec = ".", fill = TRUE, comment.char = "")
#------------#
# Exercise 1 #
#------------#
# Part 1: Use the str() function to get some information about your data set.
#         What data types are present in your data frame? Are string coded as factors
#         or character objects? If they are coded as factors go back and modify your
#         read.csv() call so that they are read in as character objects.
hmda
str(hmda)
# Part 2: Call names() on hmda. What is the result? Use the length() function to
#         calculate the number of variables in hmda.
# Part 3: Select only the following columns from the data "loan_purpose_name",
#         "action_taken_name", "applicant_ethnicity_name", "applicant_race_name_1",
#         "applicant_sex_name", "state_name", "loan_purpose_name", "loan_type_name",
#         "loan_amount_000s", "applicant_income_000s" Call the resulting data frame hmda_small
# Part 4: Create a new column that is the the actual loan amount in dollars. Run some summary
#         statistics on the loan amount. What is the minimum value loan in the data? What is the
#         maximum? What is the mean?
# Part 5: Using the unique command find out what values each of these variables takes on:
#         a. "loan_purpose_name"
#         b. "action_taken_name"
#         c. "applicant_ethnicity_name"
#         d. "applicant_race_name_1"
#         e. "applicant_sex_name"
#         f. "loan_purpose_name"
#         g. "loan_type_name"
# Part 6: a. How many loans in the data set are for each of the following:
#           "Home improvement","Refinancing","Home purchase"
#         b. How many "Application denied by financial institution"  observations were there?
#            What fraction of total observations is this?
#
# Part 7: Using the ifelse() create a new variable called race_ethnicity that is the variable
#         applicant_ethnicity_name when applicant_ethnicity_name is equal to "Hispanic or Latino"
#         and applicant_race_name_1 otherwise. Calculate summary statistics of the loan variable
#         for each racial and ethnic group. Which group has the largest average loan? Which group
#         has the largest standard deviation in loan amount?
#------------#
# Exercise 2 #
#------------#
# Part 1: Calculate the mean loan amount by state using the aggregate command.
#         Which state has the highest mean loan amount? Which state has the lowest?
# Part 2: Calculate the fraction of white loan applicants by state.
#         Which state has the highest fraction of white loan applicants? Which state has the lowest?
#------------#
# Exercise 3 #
#------------#
# Part 1: Create a bar chart of the average loan amount by racial and ethnic group. Make
#         sure your axes are properly labeled and your chart has a title.
# Part 2: Create a bar chart of the fraction of loan denied by the financial institution by racial
#         and ethnic group. Make sure your axes are properly labeled and your chart has a title.
# Part 3: Create a histogram of the loan amount.
# Part 4: Create a scatter plot of applicant income vs. loan amount. Do you see any relationship?
#         use the cor() function to calculate the correlation between the two variables.
#----------------#
# Extra Credit 1 #
#----------------#
# Explore the data some more!
#----------------#
# Extra Credit 2 #
#----------------#
# Continue working through the program we started in class 4 (eda_exercise.R)
# Download the *updated* version of the program tempalate from github and follow
# the instructions in the comments
#
# link: https://github.com/wampeh1/Ecog314_Spring2017/tree/master/lecture4
# file name: eda_exercise.R
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
hmda
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
data_url <- "hmda"
source('~/JonesVIctor Homework 4.R')
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
data_url <- "hmda"
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda") ) {
download.file(data_url, "hmda")
}
data_url <- hmda
hmda
names(hmda)
length(hmda)
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/tree/master/homework"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
data_url <- hmda
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
data_url <- hmda
hmda
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda_small")
}
data_url <- hmda_small
hmda_small
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
data_url <- hmda
hmda
#------
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
data_url <- hmda
hmda
data_url <- "https://raw.githubusercontent.com/wampeh1/Ecog314_Spring2017/master/lecture4/data/mtcars.csv"
if ( ! file.exists("mtcars.csv") ) {
download.file(data_url, "mtcars.csv")
}
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda")
}
hmda <- read.csv("hmda_small")
source('~/JonesVIctor Homework 4.R')
source('~/JonesVIctor Homework 4.R')
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda_small", stringAsFactors = FALSE)
}
hmda <- read.csv("hmda_small")
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda_small", stringAsFactors = FALSE)
}
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda_small", stringAsFactors = FALSE)
}
hmda <- read.csv("hmda_small")
str(hmda)
str(hmda)
data_url <- "https://github.com/wampeh1/Ecog314_Spring2017/blob/master/lecture4/data/hmda_small.csv"
if ( ! file.exists("hmda_small") ) {
download.file(data_url, "hmda_small", stringAsFactors = FALSE)
}
hmda <- read.csv("hmda_small")
str(hmda)
names(hmda)
length(hmda)
ncome_000s" Call the resulting data frame hmda_small
hmda$c("loan_purpose_name", "action_taken_name", "applicant_ethnicity_name", "applicant_race_name_1",
"applicant_sex_name", "state_name", "loan_purpose_name", "loan_type_name",
"loan_amount_000s", "applicant_income_000s")
?install.packages
install.packages("dplyr")
?library
lubrary(dplyr)
library(dplyr)
browsweVignettes("dplyr")
browseVignettes("dplyr")
install.package("nycflights13")
install.packages("nycflights13")
library("nycflights13")
nycflights13::flights
names(nycflights13)
names(flights)
str(flights)
colnames(flights)
nrow(flights)
nrow(flights)
dim(flights)
head(flights)
head(as.data.frame(flights))
test <- data.frame(c(1:5), c("a", "b", "c", "d". "e"))
test <- data.frame(c(1:5), c("a", "b", "c", "d", "e"))
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="author" content="Simeon Markind" />nyc
?select
flight_cols <- select(flights, year, month, day, sched_dep_time, sched_arr_time)
dim(flight_cols)
flight_cols
identical(flight_cols,baseR)
base$ <- select(flights, year, month, day, sched_dep_time, sched_arr_time)
baseR <- select(flights, year, month, day, sched_dep_time, sched_arr_time)
baseR <- select(flights, year, month, day, sched_dep_time, sched_arr_time)
identical(flight_cols, baseR)
deselect <- select(flights, -carrier, -tailnum)
names(flights)
deselect
ncol(deselect)
inClass1 <- select(flights, hour, minute, dep_delay, arr_delay, air_time)
inClass1
filter(flights, day)
?filter
?dplyr::filter
filter(flights$month)
filter(flights$month)
unique(flights$month)
Jan <- filter(flights, month == 1)
unique(flights$month)
Jan
nrow(Jan)
336000/12
ncol(Jan)
unique(Jan$month)
inClass2 <- filter(flights, day)
iple_filter <- filter(flights, day > 10, dep_delay <= 5 , !is.na(arr_time))
iple_filter
multiple_filter <- filter(flights, day > 10, dep_delay <= 5 , !is.na(arr_time)multiple_filte
multiple_filter <- filter(flights, day > 10, dep_delay <= 5 , !is.na(arr_time)
multiple_filter
multiple_filter <- filter(flights, day > 10, dep_delay <= 5, !is.na(arr_time))
multiple_filter
View(multiple_filter)
June <- filter(flights, day < 15, month > 6, dep_time > 1200)
June
filter1 <- filter(flights, day == 1 | day == 2, month == 12 | month == 11)
head(flights)
inClass4 <- filter(flights, month == 1 | month == 4 | month == 7 | month == 9, arr_time < 1200 | arr_time > 1800, dep_delay > 10, !is.na(arr_time))
head(inClass4)
inClass4 <- filter(flights, month == 1 | month == 4 | month == 7 | month == 9, arr_time < 1200 | arr_time > 1800, dep_delay > 10, !is.na(flights$arr_time))
head(inClass4)
inClass4 <- filter(flights, month == 1 | month == 4 | month == 7 | month == 9, arr_time < 1200 | arr_time > 1800, dep_delay > 10, !is.na(arr_time))
head(inClass4)
inClass4 <- filter(flights, month %in% c(1,4,7,9), arr_time < 1200 | arr_time > 1800, dep_delay > 10, !is.na(arr_time))
head(inClass4)
inClass4 <- filter(flights, month %in% c(1,4,7,9),
arr_time < 1200 | arr_time > 1800,
dep_delay > 10,
!is.na(arr_time))
head(inClass4)
?arrange
arrEx1 <- arrange(flights, dep_time, sched_dep_time, arr_time)
head(arrEx1)
arrEx1 <- arrange(flights, dep_time, sched_dep_time, arr_time)
head(arrEx1)
arrEx2 <- arrange(flights, desc(dep_time), -sched_dep_time, arr_time)
arrEx2 <- arrange(flights, desc(dep_time), -sched_dep_time, arr_time)
(arrEx2 <- arrange(flights, desc(dep_time), -sched_dep_time, arr_time))
deviance <- flights$arr_time - flights$dep_time
deviance == flights$air_time
inClass6
inClass6 <- select(flights, dep_time, arr_time, air_time)
deviance <- flights$arr_time - flights$dep_time
deviance == flights$air_time
inClass6
sum(inclass6$match)
sum(inClass6$match)
inClass6 <- mutate (flight,
deviance = arr_time - dep_time,
match = deviance == air_time)
inClass6 <- mutate(InClass6,
deviance = arr_time - dep_time,
match = deviance == air_time)
inClass6 <- mutate(InClass6,
deviance = arr_time - dep_time,
match = deviance == air_time)
inClass6 <- mutate(flights,
deviance = arr_time - dep_time,
match = deviance == air_time)
sum(inClass6$match)
summ <- summarise(flights, avg_dep_delay = mean(dep_delay, na.rm = T),
avg_arr_delay = mean(arr_delay, na.rm = T),
avg_gain = mean(arr_delay - dep_delay, na.rm = T))
?dplyr=sd
merge(my_data, my_data2)
setwd("/Volumes/VICTOR/DATA ANALYSIS WITH R/Project")
library(dplyr)
my_data <-read.csv("AA educ by MSA.csv", stringsAsFactors =T, header = T)
my_data2 <- read.csv("AA inc  by MSA.csv", stringsAsFactors =  T, header = T)
my_data3 <- read.csv("WNH educ by MSA.csv", stringsAsFactors = T, header = T)
my_data4<- read.csv("WNH inc by MSA", stringsAsFactors = T, header = T)
merge(my_data, my_data2)
merge(my_data, my_data2,
?merge
merge(my_data, my_data2,
?merge
merge(my_data, my_data2, all)
merge(my_data, my_data2, by =
data.frame(my_data)
?merge
my_data <-data.frame(read.csv("AA educ by MSA.csv", stringsAsFactors =T, header = T))
my_data <-data.frame(read.csv("AA educ by MSA.csv", stringsAsFactors =T, header = T))
my_data
merge(my_data, my_data2)
merge(my_data, my_data2)
my_data2 <- data.frame(read.csv("AA inc  by MSA.csv", stringsAsFactors =  T, header = T))
merge(my_data, my_data2)
my_data
my_data
my_data2
my_data3
my_data1 <-data.frame(read.csv("AA educ by MSA.csv", stringsAsFactors =T, header = T))
merge(my_data1, my_data2)
mergedfileaa <- merge(my_data1, my_data2)
mergedfileaa
my_dataAA <- full_join(add_rownames(my_data1) , add_rownames(my_data2), by='rowname') %>%
select(-rowname)
my_dataAA <- merge(my_data1), my_data2, by = "row", all = TRUE)
my_dataAA <- merge(my_data1, my_data2, by = "row", all = TRUE)
my_dataAA <- merge(my_data1, my_data2, by = , all = TRUE)
my_dataAA
my_dataAA <- merge(my_data1, my_data2, by = "MSA" , all = TRUE)
my_dataAA
summary(my_dataAA)
